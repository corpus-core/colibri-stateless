# This starter workflow is for a CMake project running on multiple platforms. There is a different starter workflow if you just want a single platform.
# See: https://github.com/actions/starter-workflows/blob/main/ci/cmake-single-platform.yml
name: CMake on multiple platforms

on:
  push:
    branches: ["main", "dev"]
    tags:
      - "v*" # Trigger on version tags
  pull_request:
    branches: ["main", "dev"]

jobs:
  build-embedded:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 1

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y cmake gcc-arm-none-eabi binutils-arm-none-eabi

      - name: Configure CMake
        run: |
          mkdir -p build
          cmake -B build -S . \
            -DCMAKE_TOOLCHAIN_FILE=$PWD/test/embedded/toolchain.cmake \
            -DEMBEDDED=ON \
            -DCMAKE_EXPORT_COMPILE_COMMANDS=TRUE \
            -DCMAKE_BUILD_TYPE=MinSizeRel \
            -DCURL=OFF \
            -DEVMONE=OFF \
            -DEVMLIGHT=OFF \
            -DPROOFER=OFF \
            -DCLI=OFF \
            -DINCLUDE=test/embedded
          cat build/compile_commands.json

      - name: Build verifier
        run: |
          cmake --build build --target verify_embedded.elf

      - name: Build minimal verify
        run: |
          cmake --build build --target minimal_verify.elf

      - name: Diagnostic ELF info
        run: |
          echo "Checking ELF file structure for debug purposes:"
          arm-none-eabi-readelf -S build/test/embedded/verify_embedded.elf | grep "Section" | head -1
          echo "All section headers:"
          arm-none-eabi-readelf -S build/test/embedded/verify_embedded.elf | grep -A 1 "\[" | head -20

      - name: Memory analysis
        run: |
          # Create the GitHub Step Summary
          echo "# EmbeddedMemory Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Executable Size" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Verifier" >> $GITHUB_STEP_SUMMARY
          echo "| Section | Size | Description |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|------|-------------|" >> $GITHUB_STEP_SUMMARY

          # Get size information for full verifier
          SIZE_OUTPUT=$(arm-none-eabi-size --format=berkeley build/test/embedded/verify_embedded.elf)
          TEXT_SIZE=$(echo "$SIZE_OUTPUT" | tail -1 | awk '{print $1}')
          DATA_SIZE=$(echo "$SIZE_OUTPUT" | tail -1 | awk '{print $2}')
          BSS_SIZE=$(echo "$SIZE_OUTPUT" | tail -1 | awk '{print $3}')
          TOTAL_SIZE=$(echo "$SIZE_OUTPUT" | tail -1 | awk '{print $4}')

          echo "| .text (Flash) | $(numfmt --to=iec --format="%.2f" $TEXT_SIZE) | Code |" >> $GITHUB_STEP_SUMMARY
          echo "| .data (RAM) | $(numfmt --to=iec --format="%.2f" $DATA_SIZE) | Initialized data |" >> $GITHUB_STEP_SUMMARY
          echo "| .bss (RAM) | $(numfmt --to=iec --format="%.2f" $BSS_SIZE) | Uninitialized data |" >> $GITHUB_STEP_SUMMARY
          echo "| Total | $(numfmt --to=iec --format="%.2f" $TOTAL_SIZE) | Total memory footprint |" >> $GITHUB_STEP_SUMMARY


          # Create artifact with detailed memory analysis
          mkdir -p memory_analysis
          arm-none-eabi-nm --print-size --size-sort --radix=d build/test/embedded/verify_embedded.elf > memory_analysis/symbols_by_size.txt
          arm-none-eabi-objdump -h build/test/embedded/verify_embedded.elf > memory_analysis/section_headers.txt
          arm-none-eabi-readelf -S build/test/embedded/verify_embedded.elf > memory_analysis/section_details.txt
          arm-none-eabi-size --format=berkeley build/test/embedded/verify_embedded.elf > memory_analysis/size_summary.txt
          arm-none-eabi-size --format=berkeley build/test/embedded/minimal_verify.elf >> memory_analysis/size_summary.txt

          # Create a simple metrics file for easier parsing later
          echo "{" > memory_analysis/metrics.json
          echo "  \"text_size\": $TEXT_SIZE," >> memory_analysis/metrics.json
          echo "  \"data_size\": $DATA_SIZE," >> memory_analysis/metrics.json
          echo "  \"bss_size\": $BSS_SIZE," >> memory_analysis/metrics.json
          echo "  \"total_size\": $TOTAL_SIZE," >> memory_analysis/metrics.json
          echo "  \"commit\": \"$(git rev-parse --short HEAD)\"," >> memory_analysis/metrics.json
          echo "  \"date\": \"$(git show -s --format=%ci HEAD)\"" >> memory_analysis/metrics.json
          echo "}" >> memory_analysis/metrics.json

      - name: Upload memory analysis
        uses: actions/upload-artifact@v4
        with:
          name: memory-analysis
          path: memory_analysis/

  valgrind:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install Valgrind
        run: sudo apt-get update && sudo apt-get install -y valgrind
      - name: Build minsize
        run: cmake -B build_minsize -DTEST=true -DCURL=false -DCMAKE_BUILD_TYPE=MinSizeRel -DTEST=true -DMESSAGES=false -S . && cd build_minsize && make && cd ..
      - name: Build
        run: cmake -B build -DTEST=true -DCURL=false  -DCMAKE_BUILD_TYPE=Debug -S . && cd build && make && cd ..

      - name: Run Valgrind on all test binaries
        run: |
          echo "# Valgrind Memory Check Results" > valgrind_summary.md
          echo "" >> valgrind_summary.md
          EXIT_CODE=0

          for test_binary in ./build/test/unittests/test_*; do
            if [ -x "$test_binary" ]; then
              echo "Running valgrind on $test_binary"
              TEST_NAME=$(basename "$test_binary")
              
              # Create a temporary file for valgrind output
              TEMP_OUTPUT=$(mktemp)
              
              # Run valgrind and capture both stdout and stderr
              valgrind --leak-check=full --error-exitcode=1 --track-origins=yes "$test_binary" 2>&1 | tee "$TEMP_OUTPUT"
              VALGRIND_STATUS=${PIPESTATUS[0]}
              
              # Extract valgrind-specific messages (lines starting with ==)
              VALGRIND_MESSAGES=$(grep -E "^==[0-9]+== " "$TEMP_OUTPUT" || true)
              
              if [ $VALGRIND_STATUS -ne 0 ]; then
                EXIT_CODE=1
                echo "âŒ $TEST_NAME: memory issues found:" >> valgrind_summary.md
                echo '```' >> valgrind_summary.md
                # First show the test output without valgrind messages
                grep -vE "^==[0-9]+== " "$TEMP_OUTPUT" >> valgrind_summary.md || true
                echo "" >> valgrind_summary.md
                # Then show the valgrind messages
                echo "$VALGRIND_MESSAGES" >> valgrind_summary.md
                echo '```' >> valgrind_summary.md
                echo "" >> valgrind_summary.md
              else
                echo "âœ… $TEST_NAME:  ok" >> valgrind_summary.md
              fi
              
              # Clean up temp file
              rm "$TEMP_OUTPUT"
            fi
          done

          cat valgrind_summary.md >> $GITHUB_STEP_SUMMARY
          exit $EXIT_CODE

      - name: Analyze Stack Usage for test_eth_verify_logs
        run: |
          # Define the test binary path
          TEST_BINARY="./build/test/unittests/verify_only"
          TEST_BINARY_MINSIZE="./build_minsize/test/unittests/verify_only"

          # Create directory for detailed reports
          mkdir -p memory-analysis

          # Run massif for heap analysis
          valgrind --tool=massif \
            --detailed-freq=1 \
            --max-snapshots=100 \
            --threshold=0.1 \
            --stacks=yes \
            --pages-as-heap=no \
            --heap=yes \
            --ignore-fn=dl_start \
            --ignore-fn=_dl_start \
            --ignore-fn=_dl_* \
            --ignore-fn=dl_* \
            --ignore-fn=__GI_* \
            --ignore-fn=__libc_* \
            --ignore-fn=malloc \
            --ignore-fn=calloc \
            --ignore-fn=realloc \
            --ignore-fn=free \
            --ignore-fn=__malloc_* \
            --ignore-fn=__realloc_* \
            --ignore-fn=__calloc_* \
            --ignore-fn=__free_* \
            --ignore-fn=*mmap* \
            --ignore-fn=*brk* \
            --ignore-fn=tcache* \
            --ignore-fn=sbrk \
            --ignore-fn=sysmalloc \
            --ignore-fn=_int_malloc \
            --massif-out-file=massif.out \
            $TEST_BINARY

          # Run memcheck for stack analysis
          valgrind --tool=memcheck \
            --track-origins=yes \
            --max-stackframe=8388608 \
            --main-stacksize=8388608 \
            --log-file=memcheck.out \
            --verbose \
            --trace-children=yes \
            $TEST_BINARY

          # Generate full massif report
          ms_print massif.out > memory-analysis/massif-full-report.txt

          # Create summary for GitHub
          {
            echo "# Memory Analysis Summary"
            echo ""
            echo "## Memory Usage"
            echo "| Metric | Size |"
            echo "|--------|------|"
            # Extract peak heap memory (convert to KB)
            echo "| Peak Heap | $(awk '/heap_tree=peak/{getline; split($0,a," "); print a[2]/1024" KB"}' massif.out) |"
            # Find maximum stack size across all snapshots (convert to KB)
            echo "| Peak Stack | $(awk '/mem_stacks_B/{split($0,a,"="); if(a[2]>max) max=a[2]} END{print max/1024" KB"}' massif.out) |"
            # Get executable size in KB
            echo "| Executable | $(ls -l $TEST_BINARY_MINSIZE | awk '{print int($5/1024)" KB"}') |"
            echo ""
            echo "[View detailed memory analysis](https://corpus-core.github.io/c4/memory-analysis/massif-full-report.txt)"
          } > memory_summary.md

          # Save detailed logs
          cp memcheck.out memory-analysis/
          cp massif.out memory-analysis/

          # Extract metrics for JSON format
          PEAK_HEAP=$(awk '/heap_tree=peak/{getline; split($0,a," "); print a[2]}' massif.out)
          PEAK_STACK=$(awk '/mem_stacks_B/{split($0,a,"="); if(a[2]>max) max=a[2]} END{print max}' massif.out)
          EXEC_SIZE=$(ls -l $TEST_BINARY_MINSIZE | awk '{print $5}')

          # Create JSON metrics file
          echo "{" > memory-analysis/valgrind-metrics.json
          echo "  \"peak_heap\": $PEAK_HEAP," >> memory-analysis/valgrind-metrics.json
          echo "  \"peak_stack\": $PEAK_STACK," >> memory-analysis/valgrind-metrics.json
          echo "  \"executable_size\": $EXEC_SIZE," >> memory-analysis/valgrind-metrics.json
          echo "  \"commit\": \"$(git rev-parse --short HEAD)\"," >> memory-analysis/valgrind-metrics.json
          echo "  \"date\": \"$(git show -s --format=%ci HEAD)\"" >> memory-analysis/valgrind-metrics.json
          echo "}" >> memory-analysis/valgrind-metrics.json

          # Write summary to GitHub step summary
          cat memory_summary.md >> $GITHUB_STEP_SUMMARY

      - name: Upload Memory Analysis Reports
        uses: actions/upload-artifact@v4
        with:
          name: memory-analysis-reports
          path: memory-analysis
          if-no-files-found: error

  static_analysis:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Clang Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y clang-tools clang

      - name: List Checkers
        run: scan-build --help 2>&1

      - name: Configure CMake with Scan-Build
        run: |
          mkdir -p build
          cd build

          # Define scan-build options
          SCAN_BUILD_OPTS="\
            -enable-checker alpha.core.SizeofPtr \
            -enable-checker alpha.core.TestAfterDivZero \
            -enable-checker alpha.security.ArrayBoundV2 \
            -enable-checker alpha.security.MallocOverflow \
            -enable-checker alpha.security.ReturnPtrRange \
            -enable-checker optin.performance.Padding \
            -analyzer-config aggressive-binary-operation-simplification=true \
            -analyzer-config mode=deep \
            -analyzer-config explore-paths=true \
            -analyzer-config strict-mode=true"

          # Apply scan-build to CMake configuration
          scan-build $SCAN_BUILD_OPTS cmake -DCMAKE_BUILD_TYPE=DEBUG  -DTEST=true -DCURL=false ..

      - name: Run Scan-Build
        id: scan-build
        run: |
          cd build
          # Run scan-build with the same options
          scan-build \
            --force-analyze-debug-code \
            --status-bugs \
            -v \
            -o scan-build-results \
            --exclude ../libs \
            $SCAN_BUILD_OPTS \
            make 2>&1 | tee -a scan-build-output.txt || true

          # Store the scan-build exit code
          SCAN_EXIT_CODE=${PIPESTATUS[0]}

          # Check if scan-build found no bugs (handles both formats)
          if grep -q -E "No bugs found\.|scan-build: 0 bugs found" scan-build-output.txt; then
            echo "no_bugs=true" >> $GITHUB_OUTPUT
            echo "## âœ… Static Analysis Results" > ../analysis_summary.md
            echo "" >> ../analysis_summary.md
            echo "No bugs found by static analysis." >> ../analysis_summary.md
          else
            echo "no_bugs=false" >> $GITHUB_OUTPUT
            
            # Create a summary of the issues
            echo "## ðŸ”„ Static Analysis Issues" > ../analysis_summary.md
            echo "" >> ../analysis_summary.md
            echo "[View detailed static analysis report](https://corpus-core.github.io/c4/static-analysis/analysis_summary.md)" >> ../analysis_summary.md
            echo "" >> ../analysis_summary.md
            # Organize the HTML reports for GitHub Pages
            mkdir -p static-analysis-report/report
            
            # Find the latest HTML report directory (created by scan-build)
            LATEST_REPORT=$(find scan-build-results -type d -name "20*" | sort | tail -n 1)
            
            if [ -n "$LATEST_REPORT" ] && [ -d "$LATEST_REPORT" ]; then
              # Copy the HTML report to our report directory
              cp -R $LATEST_REPORT/* static-analysis-report/report/
              
              # Create an index.html file that redirects to the actual report
              REPORT_INDEX=$(find static-analysis-report/report -name "index.html")
              REPORT_PATH=$(basename $(dirname $REPORT_INDEX))
              
              # Create a simple redirect index if needed
              if [ "$REPORT_PATH" != "report" ]; then
                echo '<!DOCTYPE html>
                <html>
                <head>
                  <meta http-equiv="refresh" content="0; url='$REPORT_PATH'/index.html">
                </head>
                <body>
                  <p>Redirecting to <a href="'$REPORT_PATH'/index.html">static analysis report</a>...</p>
                </body>
                </html>' > static-analysis-report/report/index.html
              fi
            fi
            
            # Exit with the scan-build status code if bugs were found
            exit $SCAN_EXIT_CODE
          fi

      - name: Generate Analysis Summary
        if: always()
        run: |
          # Copy analysis summary to the report directory
          mkdir -p build/static-analysis-report
          cp analysis_summary.md build/static-analysis-report/

          {
            # Include the analysis summary
            cat analysis_summary.md
            
            # Only include build output if bugs were found
            if [ "${{ steps.scan-build.outputs.no_bugs }}" != "true" ]; then
              
              # Process the output to create a markdown list with code blocks
              awk '
                BEGIN { in_issue = 0; issue_text = ""; code_block = ""; }
                
                # Skip cmake progress lines
                /^\[/ { next }
                
                # Start of a warning/error - collect the line
                /:[0-9]+:[0-9]+: (warning|error|note):/ {
                  if ($0 ~ /\/libs\//) { next }
                  
                  # If we were processing a previous issue, print it
                  if (in_issue) {
                    print issue_text
                    if (code_block != "") {
                      print "  ```c"
                      print code_block "  ```"
                      print ""
                    }
                  }
                  
                  # Extract file path and line info
                  match($0, /([^:]+):([0-9]+):([0-9]+): (warning|error|note): (.+) \[(.+)\]/, arr)
                  file = arr[1]
                  # Keep path from src/ onwards
                  sub(".*/src/", "src/", file)
                  
                  # Set icon based on issue type
                  if (arr[4] == "error") {
                    icon = "âŒ"
                  } else if (arr[4] == "warning") {
                    icon = "âš ï¸"
                  } else {
                    icon = "â„¹ï¸"
                  }
                  
                  # Format the new issue
                  issue_text = sprintf("- %s **%s** [%s]\\n  in %s:%s:%s", icon, arr[5], arr[6], file, arr[2], arr[3])
                  
                  in_issue = 1
                  code_block = ""
                  next
                }
                
                # Collect code block lines while in an issue
                in_issue && /^[ ]*[0-9]+[ ]*\|/ {
                  code_block = code_block "  " $0 "\\n"
                  # Also collect the pointer line that follows
                  getline pointer_line
                  if (pointer_line ~ /[ ]*\|/) {
                    code_block = code_block "  " pointer_line "\\n"
                  }
                  next
                }
                
                # Print the last issue when we reach the end
                END {
                  if (in_issue) {
                    print issue_text
                    if (code_block != "") {
                      print "  ```c"
                      print code_block "  ```"
                      print ""
                    }
                  }
                }
              ' build/scan-build-output.txt
            fi
          } >> $GITHUB_STEP_SUMMARY

      - name: Upload Analysis Results
        if: always()
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: static-analysis-report
          path: build/static-analysis-report
          if-no-files-found: warn

  code_coverage:
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout Project
        uses: actions/checkout@v4.2.2

      - name: Build Project
        uses: threeal/cmake-action@v2.0.0
        with:
          options: TEST=true CURL=false CMAKE_BUILD_TYPE=Debug COVERAGE=true

      - name: Test Project
        uses: threeal/ctest-action@v1.1.0
        with:
          test-dir: build/test/unittests

      - name: Check Test Coverage
        uses: threeal/gcovr-action@v1.1.0
        with:
          excludes: libs.* build.* test.* src.cli.*
          xml-out: coverage.xml

      - name: Generate HTML Coverage Report
        run: |
          # Install gcovr (should already be installed by gcovr-action, but just in case)
          pip install gcovr

          # Create coverage report directory
          mkdir -p build/coverage-report

          # Run gcovr to generate HTML report
          gcovr --exclude "libs.*" --exclude "build.*" --exclude "test.*" --exclude "src.cli.*" \
                --html-details build/coverage-report/index.html \
                --html-title "Colibri Coverage Report"

          # Generate text summary with per-file coverage
          {
            echo "## Coverage Summary by File"
            echo ""
            echo "| Status | File | Coverage |"
            echo "|--------|------|----------|"
            
            # Process gcovr output into a table with status icons
            gcovr --exclude "libs.*" --exclude "build.*" --exclude "test.*" --exclude "src.cli.*" | \
            awk '
            # Skip header lines, separator lines, and empty lines
            NR > 3 && $1 != "TOTAL" && NF > 0 && !/^-+$/ && !/^Directory:/ && !/^File.*Lines.*/ {
              # Extract file and coverage
              file=$1
              coverage=$4
              # Remove the % symbol
              gsub(/%/, "", coverage)
              # Add status icon based on coverage threshold
              if (coverage >= 70 || coverage == 100) {
                icon="âœ…"
              } else {
                icon="âš ï¸"
              }
              # Print in markdown table format
              printf "| %s | %s | %s%% |\n", icon, file, coverage
            }' >> coverage_summary.txt

            # Add total coverage at the end
            echo "" >> coverage_summary.txt
            TOTAL_COVERAGE=$(gcovr --exclude 'libs.*' --exclude 'build.*' --exclude 'test.*' --exclude 'src.cli.*' | grep 'TOTAL' | awk '{print $4}')
            echo "**Total coverage:** $TOTAL_COVERAGE" >> coverage_summary.txt
            
            # Create JSON metrics file
            TOTAL_COVERAGE_NUM=$(echo $TOTAL_COVERAGE | sed 's/%//')
            echo "{" > build/coverage-report/coverage-metrics.json
            echo "  \"total_coverage\": $TOTAL_COVERAGE_NUM," >> build/coverage-report/coverage-metrics.json
            echo "  \"commit\": \"$(git rev-parse --short HEAD)\"," >> build/coverage-report/coverage-metrics.json
            echo "  \"date\": \"$(git show -s --format=%ci HEAD)\"" >> build/coverage-report/coverage-metrics.json
            echo "}" >> build/coverage-report/coverage-metrics.json
          } > coverage_summary.txt

          # Add the summary to both the step summary and the coverage report directory
          cp coverage_summary.txt build/coverage-report/

      - name: Move Coverage Report
        run: |
          # Create the coverage report directory if it doesn't exist
          mkdir -p build/coverage-report

          # Check if the coverage report exists in the expected location
          if [ -d "build/coverage-report" ] && [ -f "build/coverage-report/index.html" ]; then
            echo "Coverage report found in build directory"
          else
            echo "Error: Coverage report not found in expected location"
            echo "Contents of build directory:"
            ls -la build/
            echo "Contents of build/coverage-report (if it exists):"
            ls -la build/coverage-report/ || true
            exit 1
          fi

      - name: Code Coverage Summary Report
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: coverage.xml
          badge: true
          format: markdown
          output: both
          thresholds: "30 50"

      - name: Upload Coverage Report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: build/coverage-report
          if-no-files-found: error

      - name: Add Coverage PR Comment
        uses: marocchino/sticky-pull-request-comment@v2
        if: github.event_name == 'pull_request'
        with:
          recreate: true
          message: |
            ## Coverage Report
            ${{ steps.coverage.outputs.message }}

            [View detailed coverage report](https://corpus-core.github.io/c4/coverage/index.html)

            <details>
            <summary>Coverage Details</summary>
            $(cat code-coverage-results.md)
            </details>
          path: code-coverage-results.md

      - name: Write to Job Summary
        run: |
          echo "## Coverage Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "[View detailed coverage report](https://corpus-core.github.io/c4/coverage/index.html)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat code-coverage-results.md >> $GITHUB_STEP_SUMMARY
          cat coverage_summary.txt >> $GITHUB_STEP_SUMMARY

  build:
    runs-on: ${{ matrix.os }}

    strategy:
      # Set fail-fast to false to ensure that feedback is delivered for all matrix combinations. Consider changing this to true when your workflow is stable.
      fail-fast: false

      # Set up a matrix to run the following 3 configurations:
      # 1. <Windows, Release, latest MSVC compiler toolchain on the default runner image, default generator>
      # 2. <Linux, Release, latest GCC compiler toolchain on the default runner image, default generator>
      # 3. <Linux, Release, latest Clang compiler toolchain on the default runner image, default generator>
      #
      # To add more build types (Release, Debug, RelWithDebInfo, etc.) customize the build_type list.
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        build_type: [Release]
        c_compiler: [gcc, clang, cl]
        include:
          - os: windows-latest
            c_compiler: cl
            cpp_compiler: cl
          - os: ubuntu-latest
            c_compiler: gcc
            cpp_compiler: g++
          - os: ubuntu-latest
            c_compiler: clang
            cpp_compiler: clang++
          - os: macos-latest
            c_compiler: clang
            cpp_compiler: clang++
        exclude:
          - os: windows-latest
            c_compiler: gcc
          - os: windows-latest
            c_compiler: clang
          - os: ubuntu-latest
            c_compiler: cl
          - os: macos-latest
            c_compiler: cl
          - os: macos-latest
            c_compiler: gcc
    steps:
      - uses: actions/checkout@v4

      - name: Set reusable strings
        # Turn repeated input strings (such as the build output directory) into step outputs. These step outputs can be used throughout the workflow file.
        id: strings
        shell: bash
        run: |
          echo "build-output-dir=${{ github.workspace }}/build" >> "$GITHUB_OUTPUT"

      - name: Configure CMake
        # Configure CMake in a 'build' subdirectory. `CMAKE_BUILD_TYPE` is only required if you are using a single-configuration generator such as make.
        # See https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html?highlight=cmake_build_type
        run: >
          cmake -B ${{ steps.strings.outputs.build-output-dir }}
          -DCMAKE_CXX_COMPILER=${{ matrix.cpp_compiler }}
          -DCMAKE_C_COMPILER=${{ matrix.c_compiler }}
          -DCMAKE_BUILD_TYPE=${{ matrix.build_type }}
          -DTEST=true
          -DCURL=false
          -S ${{ github.workspace }}

      - name: Build
        # Build your program with the given configuration. Note that --config is needed because the default Windows generator is a multi-config generator (Visual Studio generator).
        run: cmake --build ${{ steps.strings.outputs.build-output-dir }} --config ${{ matrix.build_type }}

      - name: Test
        working-directory: ${{ steps.strings.outputs.build-output-dir }}
        run: ctest  --output-junit junit_output.xml --output-on-failure --build-config ${{ matrix.build_type }}

      - name: Upload Binaries
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.os }}-${{ matrix.build_type }}-${{ matrix.c_compiler }}
          path: build/bin

      # Create release artifact for tagged versions
      - name: Create Release Archive
        if: startsWith(github.ref, 'refs/tags/v')
        run: |
          mkdir -p release-artifacts
          cd build/bin
          if [ "${{ matrix.os }}" == "windows-latest" ]; then
            7z a ../../release-artifacts/colibri-${{ matrix.os }}-${{ matrix.c_compiler }}.zip ./*
            # Verify the zip was created
            if [ ! -f "../../release-artifacts/colibri-${{ matrix.os }}-${{ matrix.c_compiler }}.zip" ]; then
              echo "Error: ZIP file was not created"
              exit 1
            fi
          else
            tar -czf ../../release-artifacts/colibri-${{ matrix.os }}-${{ matrix.c_compiler }}.tar.gz ./*
            # Verify the tar.gz was created
            if [ ! -f "../../release-artifacts/colibri-${{ matrix.os }}-${{ matrix.c_compiler }}.tar.gz" ]; then
              echo "Error: TAR.GZ file was not created"
              exit 1
            fi
          fi
          # List the contents of release-artifacts for verification
          ls -la ../../release-artifacts/
        shell: bash

      - name: Upload Build Artifacts
        if: startsWith(github.ref, 'refs/tags/v')
        uses: actions/upload-artifact@v4
        with:
          name: cmake-release-${{ matrix.os }}-${{ matrix.c_compiler }}
          path: release-artifacts/*
          if-no-files-found: error

      - name: Publish Test Report
        uses: mikepenz/action-junit-report@v5
        if: (success() || failure()) && matrix.os == 'ubuntu-latest' && matrix.c_compiler == 'clang' # only run for ubuntu-latest with clang
        with:
          report_paths: ${{ steps.strings.outputs.build-output-dir }}/junit_output.xml
        env:
          GITHUB_TOKEN: ${{ secrets.PAT_TOKEN }}

#    - name: Upload Test Results
#      uses: dorny/test-reporter@v1
#      if: success() || failure()
#      with:
#        name: ctest-results
#        path: ${{ steps.strings.outputs.build-output-dir }}/junit_output.xml
#        reporter: java-junit
#      env:
#        GITHUB_TOKEN: ${{ secrets.PAT_TOKEN }}

permissions:
  contents: write
  checks: write
  pull-requests: write
  actions: read
